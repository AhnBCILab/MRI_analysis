{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3194 entries, 0 to 3358\n",
      "Data columns (total 32 columns):\n",
      "Filename             3194 non-null object\n",
      "SubjectID            3194 non-null object\n",
      "Visit                3194 non-null object\n",
      "Group                3194 non-null object\n",
      "Age                  3194 non-null float64\n",
      "Sex                  3194 non-null object\n",
      "MMSE                 3194 non-null object\n",
      "GDSCALE              3194 non-null object\n",
      "CDR                  3194 non-null object\n",
      "NPI-Q                3194 non-null object\n",
      "FAQ                  3194 non-null object\n",
      "APOE A1              3194 non-null int64\n",
      "APOE A2              3194 non-null int64\n",
      "Study Identifer      3194 non-null int64\n",
      "Weight               3194 non-null float64\n",
      "Series Identifer     3194 non-null int64\n",
      "Acqusisition Type    2751 non-null object\n",
      "Weighting            3194 non-null object\n",
      "Pulse Sequence       3194 non-null object\n",
      "Slice Thickness      3194 non-null float64\n",
      "TE                   3194 non-null float64\n",
      "TR                   3194 non-null float64\n",
      "TI                   3194 non-null float64\n",
      "Coil                 3194 non-null object\n",
      "Flip Angle           3194 non-null float64\n",
      "Acquistion Plane     3194 non-null object\n",
      "Matrix X             3194 non-null float64\n",
      "Matrix Y             3194 non-null float64\n",
      "Matrix Z             3194 non-null float64\n",
      "Pixel Spacing X      3194 non-null float64\n",
      "Pixel Spacing Y      3194 non-null float64\n",
      "Field Strength       3194 non-null float64\n",
      "dtypes: float64(13), int64(4), object(15)\n",
      "memory usage: 823.5+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('metadata_output.csv')\n",
    "raw_data = raw_data[raw_data[\"CDR\"] != \"None\"]\n",
    "for column in raw_data.columns[32:]:\n",
    "    raw_data = raw_data[raw_data[column] != \"None\"]\n",
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_col = [\"MMSE\", \"GDSCALE\", \"CDR\", \"NPI-Q\", \"APOE A1\", \"APOE A2\", \"Weight\"]\n",
    "roi_data = raw_data[interest_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_data = roi_data.assign(CDR=lambda s: s['CDR'].astype('float'))\n",
    "roi_data = roi_data.mask(roi_data['CDR'] < 0).dropna()\n",
    "roi_data = roi_data[roi_data['Weight'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wooane21/MRI_analysis/myvenv/lib/python3.6/site-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    }
   ],
   "source": [
    "features_all = roi_data.mask(roi_data.eq(\"None\")).dropna().astype('float')\n",
    "features_all_x = features_all[list(filter(lambda x: x != \"CDR\", list(features_all.columns)))].values\n",
    "features_all_y = features_all['CDR'].values\n",
    "\n",
    "features_wo_NPI = roi_data[list(filter(lambda x: x != \"NPI-Q\", interest_col))]\n",
    "features_wo_NPI = features_wo_NPI.mask(features_wo_NPI.eq(\"None\")).dropna().astype('float')\n",
    "features_wo_NPI_x = features_all[list(filter(lambda x: x != \"CDR\", list(features_all.columns)))].values\n",
    "features_wo_NPI_y = features_all['CDR'].values\n",
    "\n",
    "features_wo_GDSCALE = roi_data[list(filter(lambda x: x != \"GDSCALE\", interest_col))]\n",
    "features_wo_GDSCALE = features_wo_GDSCALE.mask(features_wo_GDSCALE.eq(\"None\")).dropna().astype('float')\n",
    "features_wo_GDSCALE_x = features_all[list(filter(lambda x: x != \"CDR\", list(features_all.columns)))].values\n",
    "features_wo_GDSCALE_y = features_all['CDR'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "all_train_x, all_test_x, all_train_y, all_test_y = train_test_split(features_all_x, features_all_y, test_size=0.3)\n",
    "wo_NPI_train_x, wo_NPI_test_x, wo_NPI_train_y, wo_NPI_test_y = train_test_split(features_wo_NPI_x, features_wo_NPI_y, test_size=0.3)\n",
    "wo_GDS_train_x, wo_GDS_test_x, wo_GDS_train_y, wo_GDS_test_y = train_test_split(features_wo_GDSCALE_x, features_wo_GDSCALE_y, test_size=0.3)\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "all_train_y_c = lab_enc.fit_transform(all_train_y)\n",
    "all_test_y_c = lab_enc.fit_transform(all_test_y)\n",
    "wo_NPI_train_y_c = lab_enc.fit_transform(wo_NPI_train_y)\n",
    "wo_NPI_test_y_c = lab_enc.fit_transform(wo_NPI_test_y)\n",
    "wo_GDS_train_y_c = lab_enc.fit_transform(wo_GDS_train_y)\n",
    "wo_GDS_test_y_c = lab_enc.fit_transform(wo_GDS_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-Class problem\n",
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wooane21/MRI_analysis/myvenv/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/wooane21/MRI_analysis/myvenv/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/wooane21/MRI_analysis/myvenv/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: accuracy\n",
      "All features: 0.724324\n",
      "W/o NPI feature: 0.691892\n",
      "W/o GDS feature: 0.710811\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svc_all = base_estimator=SVC(kernel='rbf').fit(all_train_x, all_train_y_c)\n",
    "svc_wo_NPI = base_estimator=SVC(kernel='rbf').fit(wo_NPI_train_x, wo_NPI_train_y_c)\n",
    "svc_wo_GDS = base_estimator=SVC(kernel='rbf').fit(wo_GDS_train_x, wo_GDS_train_y_c)\n",
    "\n",
    "result_svc_all = svc_all.predict(all_test_x)\n",
    "result_svc_wo_NPI = svc_wo_NPI.predict(wo_NPI_test_x)\n",
    "result_svc_wo_GDS = svc_wo_GDS.predict(wo_GDS_test_x)\n",
    "\n",
    "acc_svc_all = accuracy_score(all_test_y_c, result_svc_all)\n",
    "acc_svc_wo_NPI = accuracy_score(wo_NPI_test_y_c, result_svc_wo_NPI)\n",
    "acc_svc_wo_GDS = accuracy_score(wo_GDS_test_y_c, result_svc_wo_GDS)\n",
    "\n",
    "print(\"Metric: accuracy\")\n",
    "print(\"All features: %f\" % acc_svc_all)\n",
    "print(\"W/o NPI feature: %f\" % acc_svc_wo_NPI)\n",
    "print(\"W/o GDS feature: %f\" % acc_svc_wo_GDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: accuracy\n",
      "All features: 0.764865\n",
      "W/o NPI feature: 0.700000\n",
      "W/o GDS feature: 0.729730\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf_all = RandomForestClassifier(n_estimators=100).fit(all_train_x, all_train_y_c)\n",
    "rf_wo_NPI = RandomForestClassifier(n_estimators=100).fit(wo_NPI_train_x, wo_NPI_train_y_c)\n",
    "rf_wo_GDS = RandomForestClassifier(n_estimators=100).fit(wo_GDS_train_x, wo_GDS_train_y_c)\n",
    "\n",
    "result_rf_all = rf_all.predict(all_test_x)\n",
    "result_rf_wo_NPI = rf_wo_NPI.predict(wo_NPI_test_x)\n",
    "result_rf_wo_GDS = rf_wo_GDS.predict(wo_GDS_test_x)\n",
    "\n",
    "acc_rf_all = accuracy_score(all_test_y_c, result_rf_all)\n",
    "acc_rf_wo_NPI = accuracy_score(wo_NPI_test_y_c, result_rf_wo_NPI)\n",
    "acc_rf_wo_GDS = accuracy_score(wo_GDS_test_y_c, result_rf_wo_GDS)\n",
    "\n",
    "print(\"Metric: accuracy\")\n",
    "print(\"All features: %f\" % acc_rf_all)\n",
    "print(\"W/o NPI feature: %f\" % acc_rf_wo_NPI)\n",
    "print(\"W/o GDS feature: %f\" % acc_rf_wo_GDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: MSE\n",
      "All features: 0.463977\n",
      "W/o NPI feature: 0.460952\n",
      "W/o GDS feature: 0.548220\n",
      "\n",
      "Metric: accuracy\n",
      "All features: 0.756757\n",
      "W/o NPI feature: 0.721622\n",
      "W/o GDS feature: 0.767568\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "rfr_all = RandomForestRegressor(n_estimators=100).fit(all_train_x, all_train_y)\n",
    "rfr_wo_NPI = RandomForestRegressor(n_estimators=100).fit(wo_NPI_train_x, wo_NPI_train_y)\n",
    "rfr_wo_GDS = RandomForestRegressor(n_estimators=100).fit(wo_GDS_train_x, wo_GDS_train_y)\n",
    "\n",
    "result_rfr_all = rfr_all.predict(all_test_x)\n",
    "result_rfr_wo_NPI = rfr_wo_NPI.predict(wo_NPI_test_x)\n",
    "result_rfr_wo_GDS = rfr_wo_GDS.predict(wo_GDS_test_x)\n",
    "\n",
    "acc_rfr_all = mean_squared_error(all_test_y_c, result_rfr_all)\n",
    "acc_rfr_wo_NPI = mean_squared_error(wo_NPI_test_y_c, result_rfr_wo_NPI)\n",
    "acc_rfr_wo_GDS = mean_squared_error(wo_GDS_test_y_c, result_rfr_wo_GDS)\n",
    "\n",
    "print(\"Metric: MSE\")\n",
    "print(\"All features: %f\" % acc_rfr_all)\n",
    "print(\"W/o NPI feature: %f\" % acc_rfr_wo_NPI)\n",
    "print(\"W/o GDS feature: %f\\n\" % acc_rfr_wo_GDS)\n",
    "\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "result_rfr_all_c = lab_enc.fit_transform([find_nearest([0, 0.5, 1, 2, 3], value) for value in result_rfr_all])\n",
    "result_rfr_wo_NPI_c = lab_enc.fit_transform([find_nearest([0, 0.5, 1, 2, 3], value) for value in result_rfr_wo_NPI])\n",
    "result_rfr_wo_GDS_c = lab_enc.fit_transform([find_nearest([0, 0.5, 1, 2, 3], value) for value in result_rfr_wo_GDS])\n",
    "\n",
    "acc_rfr_all_c = accuracy_score(all_test_y_c, result_rfr_all_c)\n",
    "acc_rfr_wo_NPI_c = accuracy_score(wo_NPI_test_y_c, result_rfr_wo_NPI_c)\n",
    "acc_rfr_wo_GDS_c = accuracy_score(wo_GDS_test_y_c, result_rfr_wo_GDS_c)\n",
    "\n",
    "print(\"Metric: accuracy\")\n",
    "print(\"All features: %f\" % acc_rfr_all_c)\n",
    "print(\"W/o NPI feature: %f\" % acc_rfr_wo_NPI_c)\n",
    "print(\"W/o GDS feature: %f\" % acc_rfr_wo_GDS_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes=5):\n",
    "        super(DNN, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_size, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, num_classes),\n",
    "            # nn.Softmax(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_ = x.float()\n",
    "        y_ = self.mlp(y_)\n",
    "        return y_\n",
    "\n",
    "class MyData(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.len = np.array(X).shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "dnn_all_train = MyData(all_train_x, all_train_y)\n",
    "dnn_all_train = DataLoader(dataset=dnn_all_train, batch_size=batch_size)\n",
    "dnn_all_test = MyData(all_test_x, all_test_y)\n",
    "dnn_all_test = DataLoader(dataset=dnn_all_test, batch_size=batch_size)\n",
    "dnn_wo_NPI_train = MyData(wo_NPI_train_x, wo_NPI_train_y)\n",
    "dnn_wo_NPI_train = DataLoader(dataset=dnn_wo_NPI_train, batch_size=batch_size)\n",
    "dnn_wo_NPI_test = MyData(wo_NPI_test_x, wo_NPI_test_y)\n",
    "dnn_wo_NPI_test = DataLoader(dataset=dnn_wo_NPI_test, batch_size=batch_size)\n",
    "dnn_wo_GDS_train = MyData(wo_GDS_train_x, wo_GDS_train_y)\n",
    "dnn_wo_GDS_train = DataLoader(dataset=dnn_wo_GDS_train, batch_size=batch_size)\n",
    "dnn_wo_GDS_test = MyData(wo_GDS_test_x, wo_GDS_test_y)\n",
    "dnn_wo_GDS_test = DataLoader(dataset=dnn_wo_GDS_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/100, Step: 0, Loss: 3.4647393226623535\n",
      "******************** Test ********************\n",
      "Step: 0, Loss: 3.7750091552734375, Accuracy: 0.03513513513513514 %\n",
      "**********************************************\n",
      "Epoch: 18/100, Step: 1000, Loss: 0.5738572478294373\n",
      "Epoch: 37/100, Step: 2000, Loss: 0.4106520116329193\n",
      "Epoch: 55/100, Step: 3000, Loss: 0.37335407733917236\n",
      "******************** Test ********************\n",
      "Step: 3000, Loss: 0.9185576438903809, Accuracy: 0.372972972972973 %\n",
      "**********************************************\n",
      "Epoch: 74/100, Step: 4000, Loss: 0.25871700048446655\n",
      "Epoch: 92/100, Step: 5000, Loss: 0.24780717492103577\n",
      "******************** Test ********************\n",
      "Step: 5400, Loss: 0.6830037236213684, Accuracy: 0.3945945945945946 %\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "model = DNN(all_train_x.shape[1]).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "max_epoch = 100\n",
    "step = 0\n",
    "for epoch in range(max_epoch):\n",
    "    for idx, (data, labels) in enumerate(dnn_all_train):\n",
    "        x, y = data.to(DEVICE), labels.to(DEVICE)\n",
    "        y_hat = model(x)\n",
    "        \n",
    "        loss = criterion(y_hat, y.long())\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print('Epoch: {}/{}, Step: {}, Loss: {}'.format(epoch, max_epoch, step, loss.item()))\n",
    "        \n",
    "        if step % 3000 == 0:\n",
    "            model.eval()\n",
    "            acc = 0.\n",
    "            with torch.no_grad():\n",
    "                for idx, (data, labels) in enumerate(dnn_all_test):\n",
    "                    x, y = data.to(DEVICE), labels.to(DEVICE)\n",
    "                    y_hat = model(x)\n",
    "                    loss = criterion(y_hat, y.long())\n",
    "                    _, indices = torch.max(y_hat, dim=-1)\n",
    "                    acc += torch.sum(indices == y).item()\n",
    "            print('*'*20, 'Test', '*'*20)\n",
    "            print('Step: {}, Loss: {}, Accuracy: {} %'.format(step, loss.item(), acc/len(all_test_y)))\n",
    "            print('*'*46)\n",
    "            model.train()\n",
    "        step += 1\n",
    "\n",
    "model.eval()\n",
    "acc = 0.\n",
    "with torch.no_grad():\n",
    "    for idx, (data, labels) in enumerate(dnn_all_test):\n",
    "        x, y = data.to(DEVICE), labels.to(DEVICE)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.long())\n",
    "        _, indices = torch.max(y_hat, dim=-1)\n",
    "        acc += torch.sum(indices == y).item()\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Step: {}, Loss: {}, Accuracy: {} %'.format(step, loss.item(), acc/len(all_test_y)))\n",
    "print('*'*46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/100, Step: 0, Loss: 1.1583975553512573\n",
      "******************** Test ********************\n",
      "Step: 0, Loss: 1.0116751194000244, Accuracy: 0.32972972972972975 %\n",
      "**********************************************\n",
      "Epoch: 18/100, Step: 1000, Loss: 0.32060495018959045\n",
      "Epoch: 37/100, Step: 2000, Loss: 0.5415362119674683\n",
      "Epoch: 55/100, Step: 3000, Loss: 0.5721131563186646\n",
      "******************** Test ********************\n",
      "Step: 3000, Loss: 0.969552755355835, Accuracy: 0.4135135135135135 %\n",
      "**********************************************\n",
      "Epoch: 74/100, Step: 4000, Loss: 0.17157284915447235\n",
      "Epoch: 92/100, Step: 5000, Loss: 0.30896511673927307\n",
      "******************** Test ********************\n",
      "Step: 5400, Loss: 1.0236629247665405, Accuracy: 0.3891891891891892 %\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "model = DNN(wo_NPI_train_x.shape[1]).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "max_epoch = 100\n",
    "step = 0\n",
    "for epoch in range(max_epoch):\n",
    "    for idx, (data, labels) in enumerate(dnn_wo_NPI_train):\n",
    "        x, y = data.to(DEVICE), labels.to(DEVICE)\n",
    "        y_hat = model(x)\n",
    "        \n",
    "        loss = criterion(y_hat, y.long())\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print('Epoch: {}/{}, Step: {}, Loss: {}'.format(epoch, max_epoch, step, loss.item()))\n",
    "        \n",
    "        if step % 3000 == 0:\n",
    "            model.eval()\n",
    "            acc = 0.\n",
    "            with torch.no_grad():\n",
    "                for idx, (data, labels) in enumerate(dnn_wo_NPI_test):\n",
    "                    x, y = data.to(DEVICE), labels.to(DEVICE)\n",
    "                    y_hat = model(x)\n",
    "                    loss = criterion(y_hat, y.long())\n",
    "                    _, indices = torch.max(y_hat, dim=-1)\n",
    "                    acc += torch.sum(indices == y).item()\n",
    "            print('*'*20, 'Test', '*'*20)\n",
    "            print('Step: {}, Loss: {}, Accuracy: {} %'.format(step, loss.item(), acc/len(wo_NPI_test_y)))\n",
    "            print('*'*46)\n",
    "            model.train()\n",
    "        step += 1\n",
    "\n",
    "model.eval()\n",
    "acc = 0.\n",
    "with torch.no_grad():\n",
    "    for idx, (data, labels) in enumerate(dnn_wo_NPI_test):\n",
    "        x, y = data.to(DEVICE), labels.to(DEVICE)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.long())\n",
    "        _, indices = torch.max(y_hat, dim=-1)\n",
    "        acc += torch.sum(indices == y).item()\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Step: {}, Loss: {}, Accuracy: {} %'.format(step, loss.item(), acc/len(wo_NPI_test_y)))\n",
    "print('*'*46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/100, Step: 0, Loss: 1.9047588109970093\n",
      "******************** Test ********************\n",
      "Step: 0, Loss: 1.9915257692337036, Accuracy: 0.0 %\n",
      "**********************************************\n",
      "Epoch: 18/100, Step: 1000, Loss: 1.0107342004776\n",
      "Epoch: 37/100, Step: 2000, Loss: 0.30254071950912476\n",
      "Epoch: 55/100, Step: 3000, Loss: 0.49131038784980774\n",
      "******************** Test ********************\n",
      "Step: 3000, Loss: 0.04911867901682854, Accuracy: 0.4135135135135135 %\n",
      "**********************************************\n",
      "Epoch: 74/100, Step: 4000, Loss: 0.1822080910205841\n",
      "Epoch: 92/100, Step: 5000, Loss: 0.3186281621456146\n",
      "******************** Test ********************\n",
      "Step: 5400, Loss: 0.02780911698937416, Accuracy: 0.40540540540540543 %\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "model = DNN(wo_GDS_train_x.shape[1]).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "max_epoch = 100\n",
    "step = 0\n",
    "for epoch in range(max_epoch):\n",
    "    for idx, (data, labels) in enumerate(dnn_wo_GDS_train):\n",
    "        x, y = data.to(DEVICE), labels.to(DEVICE)\n",
    "        y_hat = model(x)\n",
    "        \n",
    "        loss = criterion(y_hat, y.long())\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print('Epoch: {}/{}, Step: {}, Loss: {}'.format(epoch, max_epoch, step, loss.item()))\n",
    "        \n",
    "        if step % 3000 == 0:\n",
    "            model.eval()\n",
    "            acc = 0.\n",
    "            with torch.no_grad():\n",
    "                for idx, (data, labels) in enumerate(dnn_wo_GDS_test):\n",
    "                    x, y = data.to(DEVICE), labels.to(DEVICE)\n",
    "                    y_hat = model(x)\n",
    "                    loss = criterion(y_hat, y.long())\n",
    "                    _, indices = torch.max(y_hat, dim=-1)\n",
    "                    acc += torch.sum(indices == y).item()\n",
    "            print('*'*20, 'Test', '*'*20)\n",
    "            print('Step: {}, Loss: {}, Accuracy: {} %'.format(step, loss.item(), acc/len(wo_GDS_test_y)))\n",
    "            print('*'*46)\n",
    "            model.train()\n",
    "        step += 1\n",
    "\n",
    "model.eval()\n",
    "acc = 0.\n",
    "with torch.no_grad():\n",
    "    for idx, (data, labels) in enumerate(dnn_wo_GDS_test):\n",
    "        x, y = data.to(DEVICE), labels.to(DEVICE)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.long())\n",
    "        _, indices = torch.max(y_hat, dim=-1)\n",
    "        acc += torch.sum(indices == y).item()\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Step: {}, Loss: {}, Accuracy: {} %'.format(step, loss.item(), acc/len(wo_GDS_test_y)))\n",
    "print('*'*46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-Class problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_data['CDR'] = roi_data['CDR'].replace(3.0, 2.0)\n",
    "roi_data['CDR'] = roi_data['CDR'].replace(1.0, 2.0)\n",
    "roi_data['CDR'] = roi_data['CDR'].replace(0.5, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wooane21/MRI_analysis/myvenv/lib/python3.6/site-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    }
   ],
   "source": [
    "features_all = roi_data.mask(roi_data.eq(\"None\")).dropna().astype('float')\n",
    "features_all_x = features_all[list(filter(lambda x: x != \"CDR\", list(features_all.columns)))].values\n",
    "features_all_y = features_all['CDR'].values\n",
    "\n",
    "features_wo_NPI = roi_data[list(filter(lambda x: x != \"NPI-Q\", interest_col))]\n",
    "features_wo_NPI = features_wo_NPI.mask(features_wo_NPI.eq(\"None\")).dropna().astype('float')\n",
    "features_wo_NPI_x = features_all[list(filter(lambda x: x != \"CDR\", list(features_all.columns)))].values\n",
    "features_wo_NPI_y = features_all['CDR'].values\n",
    "\n",
    "features_wo_GDSCALE = roi_data[list(filter(lambda x: x != \"GDSCALE\", interest_col))]\n",
    "features_wo_GDSCALE = features_wo_GDSCALE.mask(features_wo_GDSCALE.eq(\"None\")).dropna().astype('float')\n",
    "features_wo_GDSCALE_x = features_all[list(filter(lambda x: x != \"CDR\", list(features_all.columns)))].values\n",
    "features_wo_GDSCALE_y = features_all['CDR'].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "all_train_x, all_test_x, all_train_y, all_test_y = train_test_split(features_all_x, features_all_y, test_size=0.3)\n",
    "wo_NPI_train_x, wo_NPI_test_x, wo_NPI_train_y, wo_NPI_test_y = train_test_split(features_wo_NPI_x, features_wo_NPI_y, test_size=0.3)\n",
    "wo_GDS_train_x, wo_GDS_test_x, wo_GDS_train_y, wo_GDS_test_y = train_test_split(features_wo_GDSCALE_x, features_wo_GDSCALE_y, test_size=0.3)\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "all_train_y_c = lab_enc.fit_transform(all_train_y)\n",
    "all_test_y_c = lab_enc.fit_transform(all_test_y)\n",
    "wo_NPI_train_y_c = lab_enc.fit_transform(wo_NPI_train_y)\n",
    "wo_NPI_test_y_c = lab_enc.fit_transform(wo_NPI_test_y)\n",
    "wo_GDS_train_y_c = lab_enc.fit_transform(wo_GDS_train_y)\n",
    "wo_GDS_test_y_c = lab_enc.fit_transform(wo_GDS_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wooane21/MRI_analysis/myvenv/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/wooane21/MRI_analysis/myvenv/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/wooane21/MRI_analysis/myvenv/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: accuracy\n",
      "All features: 0.737838\n",
      "W/o NPI feature: 0.721622\n",
      "W/o GDS feature: 0.691892\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svc_all = base_estimator=SVC(kernel='rbf').fit(all_train_x, all_train_y_c)\n",
    "svc_wo_NPI = base_estimator=SVC(kernel='rbf').fit(wo_NPI_train_x, wo_NPI_train_y_c)\n",
    "svc_wo_GDS = base_estimator=SVC(kernel='rbf').fit(wo_GDS_train_x, wo_GDS_train_y_c)\n",
    "\n",
    "result_svc_all = svc_all.predict(all_test_x)\n",
    "result_svc_wo_NPI = svc_wo_NPI.predict(wo_NPI_test_x)\n",
    "result_svc_wo_GDS = svc_wo_GDS.predict(wo_GDS_test_x)\n",
    "\n",
    "acc_svc_all = accuracy_score(all_test_y_c, result_svc_all)\n",
    "acc_svc_wo_NPI = accuracy_score(wo_NPI_test_y_c, result_svc_wo_NPI)\n",
    "acc_svc_wo_GDS = accuracy_score(wo_GDS_test_y_c, result_svc_wo_GDS)\n",
    "\n",
    "print(\"Metric: accuracy\")\n",
    "print(\"All features: %f\" % acc_svc_all)\n",
    "print(\"W/o NPI feature: %f\" % acc_svc_wo_NPI)\n",
    "print(\"W/o GDS feature: %f\" % acc_svc_wo_GDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: accuracy\n",
      "All features: 0.772973\n",
      "W/o NPI feature: 0.759459\n",
      "W/o GDS feature: 0.737838\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf_all = RandomForestClassifier(n_estimators=100).fit(all_train_x, all_train_y_c)\n",
    "rf_wo_NPI = RandomForestClassifier(n_estimators=100).fit(wo_NPI_train_x, wo_NPI_train_y_c)\n",
    "rf_wo_GDS = RandomForestClassifier(n_estimators=100).fit(wo_GDS_train_x, wo_GDS_train_y_c)\n",
    "\n",
    "result_rf_all = rf_all.predict(all_test_x)\n",
    "result_rf_wo_NPI = rf_wo_NPI.predict(wo_NPI_test_x)\n",
    "result_rf_wo_GDS = rf_wo_GDS.predict(wo_GDS_test_x)\n",
    "\n",
    "acc_rf_all = accuracy_score(all_test_y_c, result_rf_all)\n",
    "acc_rf_wo_NPI = accuracy_score(wo_NPI_test_y_c, result_rf_wo_NPI)\n",
    "acc_rf_wo_GDS = accuracy_score(wo_GDS_test_y_c, result_rf_wo_GDS)\n",
    "\n",
    "print(\"Metric: accuracy\")\n",
    "print(\"All features: %f\" % acc_rf_all)\n",
    "print(\"W/o NPI feature: %f\" % acc_rf_wo_NPI)\n",
    "print(\"W/o GDS feature: %f\" % acc_rf_wo_GDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: MSE\n",
      "All features: 0.188978\n",
      "W/o NPI feature: 0.192640\n",
      "W/o GDS feature: 0.204432\n",
      "\n",
      "Metric: accuracy\n",
      "All features: 0.778378\n",
      "W/o NPI feature: 0.740541\n",
      "W/o GDS feature: 0.756757\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "rfr_all = RandomForestRegressor(n_estimators=100).fit(all_train_x, all_train_y)\n",
    "rfr_wo_NPI = RandomForestRegressor(n_estimators=100).fit(wo_NPI_train_x, wo_NPI_train_y)\n",
    "rfr_wo_GDS = RandomForestRegressor(n_estimators=100).fit(wo_GDS_train_x, wo_GDS_train_y)\n",
    "\n",
    "result_rfr_all = rfr_all.predict(all_test_x)\n",
    "result_rfr_wo_NPI = rfr_wo_NPI.predict(wo_NPI_test_x)\n",
    "result_rfr_wo_GDS = rfr_wo_GDS.predict(wo_GDS_test_x)\n",
    "\n",
    "acc_rfr_all = mean_squared_error(all_test_y_c, result_rfr_all)\n",
    "acc_rfr_wo_NPI = mean_squared_error(wo_NPI_test_y_c, result_rfr_wo_NPI)\n",
    "acc_rfr_wo_GDS = mean_squared_error(wo_GDS_test_y_c, result_rfr_wo_GDS)\n",
    "\n",
    "print(\"Metric: MSE\")\n",
    "print(\"All features: %f\" % acc_rfr_all)\n",
    "print(\"W/o NPI feature: %f\" % acc_rfr_wo_NPI)\n",
    "print(\"W/o GDS feature: %f\\n\" % acc_rfr_wo_GDS)\n",
    "\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "result_rfr_all_c = lab_enc.fit_transform([find_nearest([0, 1, 2], value) for value in result_rfr_all])\n",
    "result_rfr_wo_NPI_c = lab_enc.fit_transform([find_nearest([0, 1, 2], value) for value in result_rfr_wo_NPI])\n",
    "result_rfr_wo_GDS_c = lab_enc.fit_transform([find_nearest([0, 1, 2], value) for value in result_rfr_wo_GDS])\n",
    "\n",
    "acc_rfr_all_c = accuracy_score(all_test_y_c, result_rfr_all_c)\n",
    "acc_rfr_wo_NPI_c = accuracy_score(wo_NPI_test_y_c, result_rfr_wo_NPI_c)\n",
    "acc_rfr_wo_GDS_c = accuracy_score(wo_GDS_test_y_c, result_rfr_wo_GDS_c)\n",
    "\n",
    "print(\"Metric: accuracy\")\n",
    "print(\"All features: %f\" % acc_rfr_all_c)\n",
    "print(\"W/o NPI feature: %f\" % acc_rfr_wo_NPI_c)\n",
    "print(\"W/o GDS feature: %f\" % acc_rfr_wo_GDS_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes=5):\n",
    "        super(DNN, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_size, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, num_classes),\n",
    "            # nn.Softmax(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_ = x.float()\n",
    "        y_ = self.mlp(y_)\n",
    "        return y_\n",
    "\n",
    "class MyData(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.len = np.array(X).shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "dnn_all_train = MyData(all_train_x, all_train_y)\n",
    "dnn_all_train = DataLoader(dataset=dnn_all_train, batch_size=batch_size)\n",
    "dnn_all_test = MyData(all_test_x, all_test_y)\n",
    "dnn_all_test = DataLoader(dataset=dnn_all_test, batch_size=batch_size)\n",
    "dnn_wo_NPI_train = MyData(wo_NPI_train_x, wo_NPI_train_y)\n",
    "dnn_wo_NPI_train = DataLoader(dataset=dnn_wo_NPI_train, batch_size=batch_size)\n",
    "dnn_wo_NPI_test = MyData(wo_NPI_test_x, wo_NPI_test_y)\n",
    "dnn_wo_NPI_test = DataLoader(dataset=dnn_wo_NPI_test, batch_size=batch_size)\n",
    "dnn_wo_GDS_train = MyData(wo_GDS_train_x, wo_GDS_train_y)\n",
    "dnn_wo_GDS_train = DataLoader(dataset=dnn_wo_GDS_train, batch_size=batch_size)\n",
    "dnn_wo_GDS_test = MyData(wo_GDS_test_x, wo_GDS_test_y)\n",
    "dnn_wo_GDS_test = DataLoader(dataset=dnn_wo_GDS_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/200, Step: 0, Loss: 2.517113208770752\n",
      "******************** Test ********************\n",
      "Step: 0, Loss: 3.5288872718811035, Accuracy: 0.31891891891891894 %\n",
      "**********************************************\n",
      "Epoch: 18/200, Step: 1000, Loss: 0.6974348425865173\n",
      "Epoch: 37/200, Step: 2000, Loss: 0.43364399671554565\n",
      "******************** Test ********************\n",
      "Step: 2000, Loss: 1.000658631324768, Accuracy: 0.7243243243243244 %\n",
      "**********************************************\n",
      "Epoch: 55/200, Step: 3000, Loss: 0.5758708119392395\n",
      "Epoch: 74/200, Step: 4000, Loss: 0.42220428586006165\n",
      "******************** Test ********************\n",
      "Step: 4000, Loss: 0.9092215299606323, Accuracy: 0.7351351351351352 %\n",
      "**********************************************\n",
      "Epoch: 92/200, Step: 5000, Loss: 0.4114561676979065\n",
      "Epoch: 111/200, Step: 6000, Loss: 0.5958482027053833\n",
      "******************** Test ********************\n",
      "Step: 6000, Loss: 0.9062435626983643, Accuracy: 0.7351351351351352 %\n",
      "**********************************************\n",
      "Epoch: 129/200, Step: 7000, Loss: 0.5215357542037964\n",
      "Epoch: 148/200, Step: 8000, Loss: 0.5391632318496704\n",
      "******************** Test ********************\n",
      "Step: 8000, Loss: 0.9186965823173523, Accuracy: 0.7378378378378379 %\n",
      "**********************************************\n",
      "Epoch: 166/200, Step: 9000, Loss: 0.7650241255760193\n",
      "Epoch: 185/200, Step: 10000, Loss: 0.8063194751739502\n",
      "******************** Test ********************\n",
      "Step: 10000, Loss: 0.9218053817749023, Accuracy: 0.7351351351351352 %\n",
      "**********************************************\n",
      "******************** Test ********************\n",
      "Step: 10800, Loss: 0.7376870512962341, Accuracy: 0.7081081081081081 %\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "model = DNN(all_train_x.shape[1]).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "max_epoch = 200\n",
    "step = 0\n",
    "for epoch in range(max_epoch):\n",
    "    for idx, (data, labels) in enumerate(dnn_all_train):\n",
    "        x, y = data.to(DEVICE), labels.to(DEVICE)\n",
    "        y_hat = model(x)\n",
    "        \n",
    "        loss = criterion(y_hat, y.long())\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print('Epoch: {}/{}, Step: {}, Loss: {}'.format(epoch, max_epoch, step, loss.item()))\n",
    "        \n",
    "        if step % 2000 == 0:\n",
    "            model.eval()\n",
    "            acc = 0.\n",
    "            with torch.no_grad():\n",
    "                for idx, (data, labels) in enumerate(dnn_all_test):\n",
    "                    x, y = data.to(DEVICE), labels.to(DEVICE)\n",
    "                    y_hat = model(x)\n",
    "                    loss = criterion(y_hat, y.long())\n",
    "                    _, indices = torch.max(y_hat, dim=-1)\n",
    "                    acc += torch.sum(indices == y).item()\n",
    "            print('*'*20, 'Test', '*'*20)\n",
    "            print('Step: {}, Loss: {}, Accuracy: {} %'.format(step, loss.item(), acc/len(all_test_y)))\n",
    "            print('*'*46)\n",
    "            model.train()\n",
    "        step += 1\n",
    "\n",
    "model.eval()\n",
    "acc = 0.\n",
    "with torch.no_grad():\n",
    "    for idx, (data, labels) in enumerate(dnn_all_test):\n",
    "        x, y = data.to(DEVICE), labels.to(DEVICE)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.long())\n",
    "        _, indices = torch.max(y_hat, dim=-1)\n",
    "        acc += torch.sum(indices == y).item()\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Step: {}, Loss: {}, Accuracy: {} %'.format(step, loss.item(), acc/len(all_test_y)))\n",
    "print('*'*46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/200, Step: 0, Loss: 5.73456335067749\n",
      "******************** Test ********************\n",
      "Step: 0, Loss: 6.828656196594238, Accuracy: 0.3216216216216216 %\n",
      "**********************************************\n",
      "Epoch: 18/200, Step: 1000, Loss: 0.6981197595596313\n",
      "Epoch: 37/200, Step: 2000, Loss: 0.52468341588974\n",
      "******************** Test ********************\n",
      "Step: 2000, Loss: 1.0864758491516113, Accuracy: 0.7351351351351352 %\n",
      "**********************************************\n",
      "Epoch: 55/200, Step: 3000, Loss: 0.8135815858840942\n",
      "Epoch: 74/200, Step: 4000, Loss: 0.7277891635894775\n",
      "******************** Test ********************\n",
      "Step: 4000, Loss: 0.8249022364616394, Accuracy: 0.7513513513513513 %\n",
      "**********************************************\n",
      "Epoch: 92/200, Step: 5000, Loss: 0.4796340763568878\n",
      "Epoch: 111/200, Step: 6000, Loss: 0.5599435567855835\n",
      "******************** Test ********************\n",
      "Step: 6000, Loss: 0.7297224402427673, Accuracy: 0.7405405405405405 %\n",
      "**********************************************\n",
      "Epoch: 129/200, Step: 7000, Loss: 1.0209497213363647\n",
      "Epoch: 148/200, Step: 8000, Loss: 0.5584893226623535\n",
      "******************** Test ********************\n",
      "Step: 8000, Loss: 0.6835721135139465, Accuracy: 0.7243243243243244 %\n",
      "**********************************************\n",
      "Epoch: 166/200, Step: 9000, Loss: 0.6766370534896851\n",
      "Epoch: 185/200, Step: 10000, Loss: 0.8065476417541504\n",
      "******************** Test ********************\n",
      "Step: 10000, Loss: 0.6608085632324219, Accuracy: 0.7378378378378379 %\n",
      "**********************************************\n",
      "******************** Test ********************\n",
      "Step: 10800, Loss: 0.36439162492752075, Accuracy: 0.7243243243243244 %\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "model = DNN(wo_NPI_train_x.shape[1]).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "max_epoch = 200\n",
    "step = 0\n",
    "for epoch in range(max_epoch):\n",
    "    for idx, (data, labels) in enumerate(dnn_wo_NPI_train):\n",
    "        x, y = data.to(DEVICE), labels.to(DEVICE)\n",
    "        y_hat = model(x)\n",
    "        \n",
    "        loss = criterion(y_hat, y.long())\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print('Epoch: {}/{}, Step: {}, Loss: {}'.format(epoch, max_epoch, step, loss.item()))\n",
    "        \n",
    "        if step % 2000 == 0:\n",
    "            model.eval()\n",
    "            acc = 0.\n",
    "            with torch.no_grad():\n",
    "                for idx, (data, labels) in enumerate(dnn_all_test):\n",
    "                    x, y = data.to(DEVICE), labels.to(DEVICE)\n",
    "                    y_hat = model(x)\n",
    "                    loss = criterion(y_hat, y.long())\n",
    "                    _, indices = torch.max(y_hat, dim=-1)\n",
    "                    acc += torch.sum(indices == y).item()\n",
    "            print('*'*20, 'Test', '*'*20)\n",
    "            print('Step: {}, Loss: {}, Accuracy: {} %'.format(step, loss.item(), acc/len(wo_NPI_test_y)))\n",
    "            print('*'*46)\n",
    "            model.train()\n",
    "        step += 1\n",
    "\n",
    "model.eval()\n",
    "acc = 0.\n",
    "with torch.no_grad():\n",
    "    for idx, (data, labels) in enumerate(dnn_wo_NPI_test):\n",
    "        x, y = data.to(DEVICE), labels.to(DEVICE)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.long())\n",
    "        _, indices = torch.max(y_hat, dim=-1)\n",
    "        acc += torch.sum(indices == y).item()\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Step: {}, Loss: {}, Accuracy: {} %'.format(step, loss.item(), acc/len(wo_NPI_test_y)))\n",
    "print('*'*46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/200, Step: 0, Loss: 1.7766847610473633\n",
      "******************** Test ********************\n",
      "Step: 0, Loss: 1.7486310005187988, Accuracy: 0.021621621621621623 %\n",
      "**********************************************\n",
      "Epoch: 18/200, Step: 1000, Loss: 1.053214192390442\n",
      "Epoch: 37/200, Step: 2000, Loss: 0.7726266980171204\n",
      "******************** Test ********************\n",
      "Step: 2000, Loss: 1.2004179954528809, Accuracy: 0.6891891891891891 %\n",
      "**********************************************\n",
      "Epoch: 55/200, Step: 3000, Loss: 0.5722869038581848\n",
      "Epoch: 74/200, Step: 4000, Loss: 0.6979444622993469\n",
      "******************** Test ********************\n",
      "Step: 4000, Loss: 1.0030593872070312, Accuracy: 0.7405405405405405 %\n",
      "**********************************************\n",
      "Epoch: 92/200, Step: 5000, Loss: 0.4568900465965271\n",
      "Epoch: 111/200, Step: 6000, Loss: 0.3438292443752289\n",
      "******************** Test ********************\n",
      "Step: 6000, Loss: 0.8650738596916199, Accuracy: 0.7162162162162162 %\n",
      "**********************************************\n",
      "Epoch: 129/200, Step: 7000, Loss: 0.6464823484420776\n",
      "Epoch: 148/200, Step: 8000, Loss: 0.5011182427406311\n",
      "******************** Test ********************\n",
      "Step: 8000, Loss: 0.7963533997535706, Accuracy: 0.6972972972972973 %\n",
      "**********************************************\n",
      "Epoch: 166/200, Step: 9000, Loss: 0.8094469308853149\n",
      "Epoch: 185/200, Step: 10000, Loss: 0.7821260690689087\n",
      "******************** Test ********************\n",
      "Step: 10000, Loss: 0.7633261680603027, Accuracy: 0.7027027027027027 %\n",
      "**********************************************\n",
      "******************** Test ********************\n",
      "Step: 10800, Loss: 0.19598433375358582, Accuracy: 0.7135135135135136 %\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "model = DNN(wo_GDS_train_x.shape[1]).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "max_epoch = 200\n",
    "step = 0\n",
    "for epoch in range(max_epoch):\n",
    "    for idx, (data, labels) in enumerate(dnn_wo_GDS_train):\n",
    "        x, y = data.to(DEVICE), labels.to(DEVICE)\n",
    "        y_hat = model(x)\n",
    "        \n",
    "        loss = criterion(y_hat, y.long())\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print('Epoch: {}/{}, Step: {}, Loss: {}'.format(epoch, max_epoch, step, loss.item()))\n",
    "        \n",
    "        if step % 2000 == 0:\n",
    "            model.eval()\n",
    "            acc = 0.\n",
    "            with torch.no_grad():\n",
    "                for idx, (data, labels) in enumerate(dnn_all_test):\n",
    "                    x, y = data.to(DEVICE), labels.to(DEVICE)\n",
    "                    y_hat = model(x)\n",
    "                    loss = criterion(y_hat, y.long())\n",
    "                    _, indices = torch.max(y_hat, dim=-1)\n",
    "                    acc += torch.sum(indices == y).item()\n",
    "            print('*'*20, 'Test', '*'*20)\n",
    "            print('Step: {}, Loss: {}, Accuracy: {} %'.format(step, loss.item(), acc/len(wo_GDS_test_y)))\n",
    "            print('*'*46)\n",
    "            model.train()\n",
    "        step += 1\n",
    "\n",
    "model.eval()\n",
    "acc = 0.\n",
    "with torch.no_grad():\n",
    "    for idx, (data, labels) in enumerate(dnn_wo_GDS_test):\n",
    "        x, y = data.to(DEVICE), labels.to(DEVICE)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.long())\n",
    "        _, indices = torch.max(y_hat, dim=-1)\n",
    "        acc += torch.sum(indices == y).item()\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Step: {}, Loss: {}, Accuracy: {} %'.format(step, loss.item(), acc/len(wo_GDS_test_y)))\n",
    "print('*'*46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-Fold validation with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harine/MRI_analysis/myvenv/lib/python3.6/site-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 0: 0.790323\n",
      "Acc 1: 0.756098\n",
      "Acc 2: 0.756098\n",
      "Acc 3: 0.804878\n",
      "Acc 4: 0.788618\n",
      "Acc 5: 0.780488\n",
      "Acc 6: 0.715447\n",
      "Acc 7: 0.780488\n",
      "Acc 8: 0.788618\n",
      "Acc 9: 0.853659\n",
      "Total Acc: 0.781471\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]\n",
    "\n",
    "# Data processing\n",
    "interest_col = [\"MMSE\", \"GDSCALE\", \"CDR\", \"NPI-Q\", \"APOE A1\", \"APOE A2\", \"Weight\"]\n",
    "roi_data = raw_data[interest_col]\n",
    "roi_data = roi_data.assign(CDR=lambda s: s['CDR'].astype('float'))\n",
    "roi_data = roi_data.mask(roi_data['CDR'] < 0).dropna()\n",
    "roi_data = roi_data[roi_data['Weight'] != 0]\n",
    "\n",
    "# 3-class problem\n",
    "roi_data['CDR'] = roi_data['CDR'].replace(3.0, 2.0)\n",
    "roi_data['CDR'] = roi_data['CDR'].replace(1.0, 2.0)\n",
    "roi_data['CDR'] = roi_data['CDR'].replace(0.5, 1.0)\n",
    "\n",
    "features_all = roi_data.mask(roi_data.eq(\"None\")).dropna().astype('float')\n",
    "features_all_x = features_all[list(filter(lambda x: x != \"CDR\", list(features_all.columns)))].values\n",
    "features_all_y = features_all['CDR'].values\n",
    "\n",
    "n_fold = 10\n",
    "kf = KFold(n_splits=n_fold, shuffle=True)\n",
    "total_acc = 0.\n",
    "for idx, (train_idx, test_idx) in enumerate(kf.split(features_all_x)):\n",
    "    X_train, X_test = features_all_x[train_idx], features_all_x[test_idx]\n",
    "    y_train, y_test = features_all_y[train_idx], features_all_y[test_idx]\n",
    "    \n",
    "    rfr = RandomForestRegressor(n_estimators=100).fit(X_train, y_train)\n",
    "    result = [find_nearest([0, 1, 2], value) for value in rfr.predict(X_test)]\n",
    "    acc = accuracy_score(y_test, result)\n",
    "    total_acc += acc\n",
    "    print(\"Acc %d: %f\" % (idx, acc))\n",
    "    \n",
    "total_acc /= n_fold\n",
    "print(\"Total Acc: %f\" % total_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harine/MRI_analysis/myvenv/lib/python3.6/site-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 0: 0.750000\n",
      "Acc 1: 0.837398\n",
      "Acc 2: 0.772358\n",
      "Acc 3: 0.796748\n",
      "Acc 4: 0.772358\n",
      "Acc 5: 0.699187\n",
      "Acc 6: 0.780488\n",
      "Acc 7: 0.821138\n",
      "Acc 8: 0.780488\n",
      "Acc 9: 0.796748\n",
      "Total Acc: 0.780691\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Data processing\n",
    "interest_col = [\"MMSE\", \"GDSCALE\", \"CDR\", \"NPI-Q\", \"APOE A1\", \"APOE A2\", \"Weight\"]\n",
    "roi_data = raw_data[interest_col]\n",
    "roi_data = roi_data.assign(CDR=lambda s: s['CDR'].astype('float'))\n",
    "roi_data = roi_data.mask(roi_data['CDR'] < 0).dropna()\n",
    "roi_data = roi_data[roi_data['Weight'] != 0]\n",
    "\n",
    "# 3-class problem\n",
    "roi_data['CDR'] = roi_data['CDR'].replace(3.0, 2.0)\n",
    "roi_data['CDR'] = roi_data['CDR'].replace(1.0, 2.0)\n",
    "roi_data['CDR'] = roi_data['CDR'].replace(0.5, 1.0)\n",
    "\n",
    "features_all = roi_data.mask(roi_data.eq(\"None\")).dropna().astype('float')\n",
    "features_all_x = features_all[list(filter(lambda x: x != \"CDR\", list(features_all.columns)))].values\n",
    "features_all_y = features_all['CDR'].values\n",
    "\n",
    "n_fold = 10\n",
    "kf = KFold(n_splits=n_fold, shuffle=True)\n",
    "total_acc = 0.\n",
    "for idx, (train_idx, test_idx) in enumerate(kf.split(features_all_x)):\n",
    "    X_train, X_test = features_all_x[train_idx], features_all_x[test_idx]\n",
    "    y_train, y_test = features_all_y[train_idx], features_all_y[test_idx]\n",
    "    \n",
    "    rfr = RandomForestClassifier(n_estimators=100).fit(X_train, y_train)\n",
    "    result = rfr.predict(X_test)\n",
    "    acc = accuracy_score(y_test, result)\n",
    "    total_acc += acc\n",
    "    print(\"Acc %d: %f\" % (idx, acc))\n",
    "    \n",
    "total_acc /= n_fold\n",
    "print(\"Total Acc: %f\" % total_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6972972972972973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harine/MRI_analysis/myvenv/lib/python3.6/site-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n",
      "/home/harine/MRI_analysis/myvenv/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.32878791, -0.17294972, -0.44251462, -0.90674849, -1.10437898,\n",
       "        -0.01592924],\n",
       "       [-0.02147014,  0.08756794,  0.11281184,  0.14310224,  0.18095612,\n",
       "         0.00638758],\n",
       "       [-0.30731777,  0.08538179,  0.32970278,  0.76364625,  0.92342286,\n",
       "         0.00954166]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Data processing\n",
    "interest_col = [\"MMSE\", \"GDSCALE\", \"CDR\", \"NPI-Q\", \"APOE A1\", \"APOE A2\", \"Weight\"]\n",
    "roi_data = raw_data[interest_col]\n",
    "roi_data = roi_data.assign(CDR=lambda s: s['CDR'].astype('float'))\n",
    "roi_data = roi_data.mask(roi_data['CDR'] < 0).dropna()\n",
    "roi_data = roi_data[roi_data['Weight'] != 0]\n",
    "\n",
    "# 3-class problem\n",
    "roi_data['CDR'] = roi_data['CDR'].replace(3.0, 2.0)\n",
    "roi_data['CDR'] = roi_data['CDR'].replace(1.0, 2.0)\n",
    "roi_data['CDR'] = roi_data['CDR'].replace(0.5, 1.0)\n",
    "\n",
    "features_all = roi_data.mask(roi_data.eq(\"None\")).dropna().astype('float')\n",
    "features_all_x = features_all[list(filter(lambda x: x != \"CDR\", list(features_all.columns)))].values\n",
    "features_all_y = features_all['CDR'].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "all_train_x, all_test_x, all_train_y, all_test_y = train_test_split(features_all_x, features_all_y, test_size=0.3)\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='multinomial').fit(all_train_x, all_train_y)\n",
    "result = clf.predict(all_test_x)\n",
    "print(accuracy_score(all_test_y, result))\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
